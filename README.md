# Unc-Tube
Developed by Khush Mehta and Ethan Olchik for RoyalHackaway v9.

# Spec
Tagline: Preserving the wisdom of the past with the voices of today.1. Executive SummaryEchoes is a generative oral history platform that allows families to preserve and interact with their heritage. By ingesting massive amounts of raw family recordings (audio/video), the app creates a "Living Legacy" where future generations can have real-time, voice-to-voice conversations with a digital persona of their ancestors, grounded entirely in their actual lived experiences.2. Target User PersonaThe Archivist: A parent or grandparent who wants to record their stories before they are lost.The Seeker: A grandchild or descendant (ages 10–40) looking for connection, advice, or family history in a format more engaging than a photo album.3. Functional RequirementsA. The Ingest (The "Memory Wall")Video/Audio Upload: Support for bulk upload of .mp4, .mov, and .mp3 files.Contextual Processing: Gemini 2.5 Pro analyzes the footage to create a "World Knowledge" base of the person’s life.Voice Fingerprinting: Automatic extraction of a 60-second "clean" audio clip for ElevenLabs Instant Voice Cloning.B. The Interaction (The "Portal")Voice-First Interface: A "Tap-to-Talk" button for the user to ask questions.Real-time Response: A low-latency bridge where the ancestor "speaks" back.Visual Citations: While the AI speaks, the UI displays the specific timestamp/clip of the original video where that memory was found.4. Technical ArchitectureFrontend: Next.js 14+ (App Router), Tailwind CSS, Framer Motion (for "pulse" animations).Backend: FastAPI (Python 3.11+).AI Reasoning: Google Gemini 2.5 Pro API.Feature: Explicit Context Caching to store the 1M+ tokens of video data for 60-minute sessions.AI Voice: ElevenLabs API.Model: eleven_turbo_v2_5 (for < 400ms latency).Feature: Instant Voice Cloning (IVC).Storage: Google Cloud Storage (for video files) and Supabase (for user metadata).5. Data Schema (Simplified)EntityAttributesProfileid, name, birth_year, bio_summary, voice_id (ElevenLabs)Memory_Sourceid, profile_id, file_url, gemini_file_uri, durationSession_Cacheprofile_id, cache_name (Gemini Resource ID), expire_time6. Development Roadmap (The 24-Hour Sprint)TimeGoal0h - 4hData Plumbing: Set up Gemini File API upload and verify "Reasoning" over 1 hour of video.4h - 8hVocal Setup: Implement ElevenLabs IVC. Manually clone a voice and test streaming via a script.8h - 14hThe Bridge: Build the FastAPI WebSocket that pipes Gemini tokens -> ElevenLabs Stream.14h - 18hFrontend Polish: Build the "Portal" UI. Add the video citation player.18h - 24hBuffer/Demo Prep: Fix latency issues. Record a "Golden Path" demo video in case of Wi-Fi failure.7. Success Metrics for JudgesEmotional Impact: Does the voice sound like a "person" or a "computer"?Accuracy: Does the AI correctly remember facts from the 3rd hour of the uploaded footage?Latency: Does the ancestor respond in under 2 seconds?